{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./notebooks/preprocessed_data.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int16)\n",
    "    return df\n",
    "\n",
    "data = downcast_dtypes(data)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data.query('date_block_num >= 3 and date_block_num < 28').copy()\n",
    "validation_set = data.query('date_block_num >= 28 and date_block_num < 33').copy()\n",
    "test_set = data.query('date_block_num == 33').copy()\n",
    "\n",
    "print('Train set records:', train_set.shape[0])\n",
    "print('Validation set records:', validation_set.shape[0])\n",
    "print('Test set records:', test_set.shape[0])\n",
    "\n",
    "print('Train set records: %s (%.f%% of complete data)' % (train_set.shape[0], ((train_set.shape[0]/data.shape[0])*100)))\n",
    "print('Validation set records: %s (%.f%% of complete data)' % (validation_set.shape[0], ((validation_set.shape[0]/data.shape[0])*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shop_id  item_id\n",
       "ID                  \n",
       "0         5     5037\n",
       "1         5     5320\n",
       "2         5     5233\n",
       "3         5     5232\n",
       "4         5     5268"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with test competition data to ensure test data is in the correct order.\n",
    "\n",
    "# Load in competition test  dataset proviided\n",
    "test_competition  = pd.read_csv('./input/test.csv', \n",
    "                    dtype={'ID': 'int16', 'shop_id': 'int16', 'item_id': 'int16'}\n",
    "                   ).set_index('ID')\n",
    "test_competition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_type_code</th>\n",
       "      <th>item_category_subtype_code</th>\n",
       "      <th>shop_city_code</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>item_platform</th>\n",
       "      <th>item_digital</th>\n",
       "      <th>...</th>\n",
       "      <th>price_increase</th>\n",
       "      <th>price_decrease</th>\n",
       "      <th>item_cnt_min</th>\n",
       "      <th>item_cnt_max</th>\n",
       "      <th>item_cnt_mean</th>\n",
       "      <th>item_cnt_std</th>\n",
       "      <th>item_cnt_shifted1</th>\n",
       "      <th>item_cnt_shifted2</th>\n",
       "      <th>item_cnt_shifted3</th>\n",
       "      <th>item_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25990.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7191.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>942.0</td>\n",
       "      <td>3854.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  item_category_type_code  item_category_subtype_code  \\\n",
       "0        5     5037                        0                           0   \n",
       "1        5     5320                        0                           0   \n",
       "2        5     5233                        0                           0   \n",
       "3        5     5232                        3                          16   \n",
       "4        5     5268                        0                           0   \n",
       "\n",
       "   shop_city_code  item_category_id  year  month  item_platform  item_digital  \\\n",
       "0               0                 0     0      0              0             0   \n",
       "1               0                 0     0      0              0             0   \n",
       "2               0                 0     0      0              0             0   \n",
       "3              10                23  2015      9              0             0   \n",
       "4               0                 0     0      0              0             0   \n",
       "\n",
       "   ...  price_increase  price_decrease  item_cnt_min  item_cnt_max  \\\n",
       "0  ...             0.0        25990.00           0.0           0.0   \n",
       "1  ...             0.0            0.00           0.0           0.0   \n",
       "2  ...             0.0         7191.75           0.0           0.0   \n",
       "3  ...           942.0         3854.00           1.0           1.0   \n",
       "4  ...             0.0            0.00           0.0           0.0   \n",
       "\n",
       "   item_cnt_mean  item_cnt_std  item_cnt_shifted1  item_cnt_shifted2  \\\n",
       "0            0.0           0.0                0.0                0.0   \n",
       "1            0.0           0.0                0.0                0.0   \n",
       "2            0.0           0.0                0.0                0.0   \n",
       "3            1.0           0.0                1.0                0.0   \n",
       "4            0.0           0.0                0.0                0.0   \n",
       "\n",
       "   item_cnt_shifted3  item_trend  \n",
       "0                0.0         0.0  \n",
       "1                0.0         0.0  \n",
       "2                0.0         0.0  \n",
       "3                0.0         0.0  \n",
       "4                0.0         0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge and check\n",
    "test_set=pd.read_csv('./data/output/test_X.csv')\n",
    "test_X = pd.merge(test_competition, test_set, on=['shop_id', 'item_id'], how='left')\n",
    "print(len(test_X))\n",
    "test_X=test_X.drop(['Unnamed: 0'], axis=1)\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and Y Subsets for train, val and test\n",
    "train_X = train_set.drop(['date_block_num', 'sum_item_cnt_next_month'], axis=1)\n",
    "train_Y = train_set['sum_item_cnt_next_month']\n",
    "\n",
    "validation_X = validation_set.drop(['date_block_num', 'sum_item_cnt_next_month'], axis=1)\n",
    "validation_Y = validation_set['sum_item_cnt_next_month']\n",
    "\n",
    "test_X = test_X.drop(['date_block_num', 'sum_item_cnt_next_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too slow so will not replace missing values with mean\n",
    "datasets = [train_X, train_Y, validation_X, validation_Y, test_X]\n",
    "\n",
    "# Replace missing values with the median of the column. \n",
    "for dataset in datasets:\n",
    "    dataset.fillna(dataset.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check number we have no na.\n",
    "print(\"Train X Null:\", train_X.isnull().sum().sum())\n",
    "print(\"Test X Null:\", validation_X.isnull().sum().sum())\n",
    "print(\"Test X Null:\", test_X.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check number we have no na.\n",
    "print(\"Train Y Null:\", train_Y.isnull().sum())\n",
    "print(\"Test X Null:\", validation_Y.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check the order\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check the order\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check the order\n",
    "validation_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Build output directory\n",
    "data_dir = './data/output/'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes as csv files \n",
    "pd.DataFrame(train_X).to_csv(os.path.join(data_dir, 'train_X.csv'), header=True, index=True)\n",
    "pd.DataFrame(train_Y).to_csv(os.path.join(data_dir, 'train_Y.csv'), header=True, index=True)\n",
    "\n",
    "pd.DataFrame(validation_X).to_csv(os.path.join(data_dir, 'validation_X.csv'), header=True, index=True)\n",
    "pd.DataFrame(validation_Y).to_csv(os.path.join(data_dir, 'validation_Y.csv'), header=True, index=True)\n",
    "\n",
    "pd.DataFrame(test_X).to_csv(os.path.join(data_dir, 'test_X.csv'), header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train_set.drop(['date_block_num'], axis=1)\n",
    "validation=validation_set.drop(['date_block_num'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./data/output/train.csv', index=False)\n",
    "validation.to_csv('./data/output/validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler,MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "import argparse\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as   pd\n",
    "train=pd.read_csv('./data/output/train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train[['item_category_type_code', 'item_category_subtype_code', 'item_id',\n",
    "       'shop_id', 'shop_city_code', 'item_category_id', 'year', 'month',\n",
    "       'item_platform', 'item_digital', 'item_lang', 'sum_item_price',\n",
    "       'mean_item_price', 'sum_item_count', 'mean_item_count', 'transactions',\n",
    "       'item_price_unit', 'hist_min_item_price',\n",
    "       'hist_max_item_price', 'price_increase', 'price_decrease',\n",
    "       'item_cnt_min', 'item_cnt_max', 'item_cnt_mean', 'item_cnt_std',\n",
    "       'item_cnt_shifted1', 'item_cnt_shifted2', 'item_cnt_shifted3',\n",
    "       'item_trend']]\n",
    "y_train=train['sum_item_cnt_next_month'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation=pd.read_csv('./data/output/validation.csv')\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation=validation[['item_category_type_code', 'item_category_subtype_code', 'item_id',\n",
    "       'shop_id', 'shop_city_code', 'item_category_id', 'year', 'month',\n",
    "       'item_platform', 'item_digital', 'item_lang', 'sum_item_price',\n",
    "       'mean_item_price', 'sum_item_count', 'mean_item_count', 'transactions',\n",
    "       'item_price_unit', 'hist_min_item_price',\n",
    "       'hist_max_item_price', 'price_increase', 'price_decrease',\n",
    "       'item_cnt_min', 'item_cnt_max', 'item_cnt_mean', 'item_cnt_std',\n",
    "       'item_cnt_shifted1', 'item_cnt_shifted2', 'item_cnt_shifted3',\n",
    "       'item_trend']]\n",
    "y_validation=validation['sum_item_cnt_next_month'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first base catboost regression running by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Build output directory\n",
    "model_dir = './models/output/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "\n",
    " \n",
    "# define and train model\n",
    "model = CatBoostRegressor()\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_validation, y_validation), logging_level='Silent') \n",
    "\n",
    "logging.info('validating model')\n",
    "abs_err = np.abs(model.predict(X_validation) - y_validation)\n",
    "\n",
    "# print couple perf metrics\n",
    "for q in [10, 50, 90]:\n",
    "    logging.info('AE-at-' + str(q) + 'th-percentile: '\n",
    "        + str(np.percentile(a=abs_err, q=q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# print abs error\n",
    "logging.info('validating model')\n",
    "abs_err = np.abs(model.predict(X_validation) - y_validation)\n",
    "\n",
    "# print couple perf metrics\n",
    "for q in [10, 50, 90]:\n",
    "    logging.info('AE-at-' + str(q) + 'th-percentile: '\n",
    "        + str(np.percentile(a=abs_err, q=q)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "y_predict=model.predict(X_validation)\n",
    "print('Model  validation rmse:', np.sqrt(mean_squared_error(y_validation, y_predict)))\n",
    "print('Model  validation mae:', mean_absolute_error(y_validation, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in [10, 50, 90]:\n",
    "    print(str(np.percentile(a=abs_err, q=q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_savepath = os.path.join(model_dir)\n",
    "  # Save our model\n",
    "pickle.dump(model, open( 'CB_MODEL.pickle', \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The secong runningv of catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cat_columns = [i for i, col in enumerate(X_train) if not issubclass(X_train[col].dtype.type, np.floating)]\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cat_columns:\n",
    "    print(X_train[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_params = dict(\n",
    "    random_state=242,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=20,\n",
    "    verbose=10,\n",
    "    learning_rate=0.1,\n",
    "    iterations=200,\n",
    ")\n",
    "\n",
    "clf = CatBoostRegressor(**clf_params)\n",
    "\n",
    "fit_params = dict(\n",
    "    X=X_train, \n",
    "    y=y_train,\n",
    "    cat_features=cat_columns,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "clf.fit(**fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.read_csv('./data/output/test_X.csv')\n",
    "X_test=X_test.drop(['Unnamed: 0'], axis=1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.read_csv('./input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in clf.get_feature_importance(prettified=True):\n",
    "     print(i.ljust(20), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j, value in clf.get_feature_importance(fstr_type=\"Interaction\", prettified=True)[:10]:\n",
    "    print(X_train.columns[i].ljust(20), X_train.columns[j].ljust(20), value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('LR', LinearRegression()),\n",
    "          ('LASSO', Lasso()),\n",
    "          ('EN', ElasticNet()),\n",
    "          ('KNN', KNeighborsRegressor()),\n",
    "          ('CART', DecisionTreeRegressor()),\n",
    "          ('S-LR', Pipeline([('Scaler', StandardScaler()), ('LR', LinearRegression())])),\n",
    "          ('S-LASSO', Pipeline([('Scaler', StandardScaler()), ('LASSO', Lasso())])),\n",
    "          ('S-EN', Pipeline([('Scaler', StandardScaler()), ('EN', ElasticNet())])),\n",
    "          ('S-KNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsRegressor())])),\n",
    "          ('S-CART', Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeRegressor())])), \n",
    "          ('S-SVR', Pipeline([('Scaler', StandardScaler()), ('SVR', SVR(gamma='auto'))])), \n",
    "          ('S-AB', Pipeline([('Scaler', StandardScaler()), ('AB', AdaBoostRegressor())])), \n",
    "          ('S-GBM', Pipeline([('Scaler', StandardScaler()), ('GBM', GradientBoostingRegressor())])), \n",
    "          ('S-RF', Pipeline([('Scaler', StandardScaler()), ('RF', RandomForestRegressor(n_estimators=10))])), \n",
    "          ('S-ET', Pipeline([('Scaler', StandardScaler()), ('ET', ExtraTreesRegressor(n_estimators=10))]))]\n",
    "\n",
    "# ('SVR', SVR(gamma='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler,MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,4), dpi= 100, facecolor='lightblue', edgecolor='w')\n",
    "fig.suptitle('Algorithm Performance Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45d10cd5f894558d1f93644af3c8d35e5802431c095f3d8a35e8d039b16a3fad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
